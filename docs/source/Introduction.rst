1. INTRODUCTION
=====

Artificial intelligence (AI) systems have become a reality and affect our lives in many important ways. Data are at the core of artificial intelligence and machine learning (AI-ML) models; they are the main resource which enables AI-ML models to learn and evolve, allowing them to solve classification, prediction and anomaly detection tasks. Collecting, preparing and manag- ing the data assets needed to train and deploy effective AI-ML models is a challenge. It is important that performance is achieved while making sure that AI-ML models abide by data protection regulations. Data usage is a fundamental aspect to consider when AI-ML systems are designed, imple- mented and operationalised. Being aware of data management problems allows organisations and individuals to understand and follow how their data are collected, transmitted, stored, processed and exploited by AI-ML- powered systems. Anyone who plans to implement such systems should be fully aware of all challenges related to data management in order to ensure consistent and sustainable AI-ML deployment.

This document is for data owners and organisations wishing to adopt and deploy AI-ML models using these data. It discusses how data assets are used in the AI-ML models’ life cycle and highlights the best practices for using them.

Throughout the document, the term data will be used to define the rep- resentation of facts, measurements and various other types of information, while the term data asset will designate the incarnation of data in a format that is suitable for management, storage and processing within information and communication technology (ICT) systems. The document presents data management practices starting from the life cycle of AI-ML models that rely on such data. Indeed, one of the most common pitfalls is to use data that are not suitable for a given stage of AI-ML model development, or data that are not suitable at all, and then expect reasonable performance. It is impor- tant to realise that increasing data quantity does not usually mitigate the problem of having low-quality data. As an introduction to the overall data landscape, the next section provides a short introduction to data types. Then the chapter describes a reference life cycle for AI-ML models, which will be used throughout the document to map data assets to AI-ML models’ development stages, explain the role of the data assets and describe the best practices for their collection and management.


1.1	TYPES OF DATA
-------
Data can be classified into two main categories, based on the way they are organised. The first category is structured data, which is data formatted in such a way that each data item has the same standard, predefined struc- ture, usually described via metadata.

Structured data are easy to index, search and manipulate due to their predefined structure. Typical examples of structured data are relational da- tabases, where data entities (e.g., the employees of a company) are repre- sented by tables whose rows correspond each to a data item (the individual employee), while columns represent attributes (e.g., each employee’s name, age, gender). Attributes belong to elementary data types1 (e.g., integer, date, string and timestamps). The structure of each table is described by an es- sential metadata item, called the database’s schema.

The second data category is unstructured data, where each data item can have a different format and size, without a clear predefined structure. Un- structured data are usually more difficult to deal with, because they require preprocessing to extract key information from them. Examples of unstruc- tured data range from text documents and web pages to audio recordings. Advanced techniques such as natural language processing (NLP) allow for the extraction of key information from unstructured text.

For both data categories, we can distinguish between numerical and cat- egorical attributes. This distinction is of capital importance for data rep- resentation and for later processing.


1.2	DATA QUALITY
---------
A well-known saying in the realm of computing is ‘garbage in, garbage out’, meaning that if you feed any system or algorithm with low-quality data, the output will also be of low quality. AI-ML systems are no exception: they are not able to magically extract valuable insight from low-quality data, nor can they perform well without large quantities of high-quality data. Let us now list and describe some types of low-quality data that, when fed to AI-ML models, usually result in poor-quality output.

•	Redundant, Outdated or Trivial (ROT) data. . It is very easy and common to duplicate data or have the same (or similar) data collected by multiple entities. While the size of data is an important factor, redundant data are not useful for AI applications. Having diverse and comprehensive data is much more effective for AI-ML applications than a large set of redundant data.
•	Dark Data. This term refers to data collected and stored by an organiza- tion but never used. Often, data ends up unused because it is collected without a clear purpose, clobbering up the ICT infrastructure of organ- izations that do not have the proper skill level to use the data or cannot make the resource and time investment to tap into it. Other times, dark data originate from data collection procedures carried out carelessly, without upholding any collection best practice or standard. Dark data do not just lay dormant: they can become harmful to organizations. Indeed, storing dark data and maintaining the platforms that hosts them may have a non-negligible cost. While there is no clear answer on how to deal with dark data, simply deleting them can often save organizations time and money.
Generally speaking, it is possible to consider data quality as a series of di- mensions describing the quality of the information fed to (and produced by) an AI-ML model; that is, a measure of the success of the system utilizing this information. Therefore, both input and output data can be considered products with a certain quality. We now list a few aspects of data quality that should be pursued when selecting raw data. The most common ones are completeness, consistency, fitness for use, relevance and timeliness. For the purposes of this document, two additional aspects of data quality are significant: uncertainty and vagueness, which can be seen as two different aspects of indeterminacy, i.e. how much it is known about the consequences of exchanging a data item. a message. Uncertainty is mainly related to the
 
error or imprecision associated with raw data, while vagueness is a inherent issue of categorical values (for example, in the sentence “long text”, how many characters does “long” mean?). In the case of information expressed as text, one can distinguish between uncertainty due to the writing style (imprecision, vagueness, polysemy) and uncertainty due to the text content (for example “Mary gave Sally her book”).


1.3	THE AI-ML LIFE CYCLE
-------
We are now ready to discuss the different data assets generated and used by AI-ML applications. Our discussion will be driven by a basic notion of systems engineering: the development life cycle, which is used to designate the process of planning, developing, testing and deploying an information system. The AI-ML applications life cycle (in short, the AI-ML life cycle) de- fines the phases that organisations follow to take advantage of supervised machine learning (ML) models to derive practical business value. Most of these stages use and/or generate specific data assets, whose careful man- agement is the goal of this document. The AI-ML life cycle covers only a part of the AI applications landscape; other types of AI models will be discussed in Section 9. Figure 1.3 shows the different stages of the AI-ML life cycle.

In this chapter, we provide a short definition of each stage and outline the individual steps it involves (‘Phase in a Nutshell’). For the sake of clarity, we also present an instance of each stage within the framework of a running example concerning a sample AI-ML application. We start by providing a general description of the running example. Then, for each phase of the AI- ML life cycle, we will provide a short description of the phase in the context of our running example (under the title ‘Phase in Our Running Example’). This description should help the reader to understand which data assets are concretely needed at each phase and how they are used.

1.3.1 A Running Example for the AI-ML Life cycle
~~~~~~~~~~~
The ACME oil field services company wants to prevent the failure of its mechanical equipment. ACME uses a high-speed rotating machine (in- ternally called a type-A rotatory) to mix components with water to make a frothy mix used to produce shale gas. Rotating machines of type A run for weeks without interruptions, leading to frequent breakdowns. The need to find a solution to predict failure of the equipment is dire, since it is a critical component for oil and gas exploration. ACME intends to develop a AI-ML model called a binary predictor2 that will run continu- ously and assign to each ACME rotating machine a label regarding the next failure (either IMMINENT or NOT-IMMINENT). Machines labelled IM- MINENT are to be immediately stopped for maintenance in the hope that their downtime due to maintenance will be shorter than the downtime that would result from breakdown. The performance of the AI predictor will be validated by comparing the total downtime with the AI predictor in operation to downtime without the predictor, obtained from historical data. Any change (positive or negative) observed when using the AI pre- dictor will indicate the performance gain or loss.

1.3.2 Business Goal Definition
~~~~~~~~~~~
Before carrying out any development or deployment of AI applications, it is important that all stakeholders fully understand the business con- text of the AI application and the data required to achieve the AI appli- cation’s business goals, as well as the business metrics to be used to assess the degree to which these goals have been achieved.
